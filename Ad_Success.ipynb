{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDGScuYJ3xKy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnT_tZ-U4H_d"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/content/Train.csv')\n",
    "test_df = pd.read_csv('/content/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipfm_qI8tqO_"
   },
   "outputs": [],
   "source": [
    "# saving id of testset for future use\n",
    "id = test_df.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "UfTR0PQw4Mg0",
    "outputId": "af2fe79d-656e-4f20-95f1-819f73929e59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>realtionship_status</th>\n",
       "      <th>industry</th>\n",
       "      <th>genre</th>\n",
       "      <th>targeted_sex</th>\n",
       "      <th>average_runtime(minutes_per_week)</th>\n",
       "      <th>airtime</th>\n",
       "      <th>airlocation</th>\n",
       "      <th>ratings</th>\n",
       "      <th>expensive</th>\n",
       "      <th>money_back_guarantee</th>\n",
       "      <th>netgain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19717</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>Primetime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31593</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Pharma</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>Primetime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5681</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>Primetime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15491</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Political</td>\n",
       "      <td>Infomercial</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Primetime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23587</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Pharma</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>Primetime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    realtionship_status  ... money_back_guarantee netgain\n",
       "0  19717  Married-spouse-absent  ...                   No   False\n",
       "1  31593     Married-civ-spouse  ...                   No   False\n",
       "2   5681               Divorced  ...                  Yes   False\n",
       "3  15491              Separated  ...                   No   False\n",
       "4  23587     Married-civ-spouse  ...                   No    True\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "UJ8422L24QEe",
    "outputId": "42a2d883-2806-4ac5-96bd-338fe04a81af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                   0\n",
       "realtionship_status                  0\n",
       "industry                             0\n",
       "genre                                0\n",
       "targeted_sex                         0\n",
       "average_runtime(minutes_per_week)    0\n",
       "airtime                              0\n",
       "airlocation                          0\n",
       "ratings                              0\n",
       "expensive                            0\n",
       "money_back_guarantee                 0\n",
       "netgain                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "6YxZKQy0vMFP",
    "outputId": "476d1a20-3b25-4f2d-9cec-11a30e0c1d29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Cambodia', 'Cambodia'),\n",
       " ('Canada', 'Canada'),\n",
       " ('China', 'China'),\n",
       " ('Columbia', 'Columbia'),\n",
       " ('Cuba', 'Cuba'),\n",
       " ('Dominican-Republic', 'Dominican-Republic'),\n",
       " ('Ecuador', 'Ecuador'),\n",
       " ('El-Salvador', 'El-Salvador'),\n",
       " ('England', 'England'),\n",
       " ('France', 'France'),\n",
       " ('Germany', 'Germany'),\n",
       " ('Greece', 'Greece'),\n",
       " ('Guatemala', 'Guatemala'),\n",
       " ('Haiti', 'Haiti'),\n",
       " ('Holand-Netherlands', 'Honduras'),\n",
       " ('Honduras', 'Hong'),\n",
       " ('Hong', 'Hungary'),\n",
       " ('Hungary', 'India'),\n",
       " ('India', 'International'),\n",
       " ('International', 'Iran'),\n",
       " ('Iran', 'Ireland'),\n",
       " ('Ireland', 'Italy'),\n",
       " ('Italy', 'Jamaica'),\n",
       " ('Jamaica', 'Japan'),\n",
       " ('Japan', 'Laos'),\n",
       " ('Laos', 'Mexico'),\n",
       " ('Mexico', 'Nicaragua'),\n",
       " ('Nicaragua', 'Outlying-US(Guam-USVI-etc)'),\n",
       " ('Outlying-US(Guam-USVI-etc)', 'Peru'),\n",
       " ('Peru', 'Philippines'),\n",
       " ('Philippines', 'Poland'),\n",
       " ('Poland', 'Portugal'),\n",
       " ('Portugal', 'Puerto-Rico'),\n",
       " ('Puerto-Rico', 'Scotland'),\n",
       " ('Scotland', 'South'),\n",
       " ('South', 'Taiwan'),\n",
       " ('Taiwan', 'Thailand'),\n",
       " ('Thailand', 'Trinadad&Tobago'),\n",
       " ('Trinadad&Tobago', 'United-States'),\n",
       " ('United-States', 'Vietnam'),\n",
       " ('Vietnam', 'Yugoslavia')}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(zip(train_df.airlocation.value_counts().sort_index().index,test_df.airlocation.value_counts().sort_index().index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qW6qxeo1ve45"
   },
   "source": [
    "From the above pairs of airlocation in training and testing set, we can observe that 'Holand-Netherlands' is missing in the testing set. While performing OneHotEncoder or Pandas' get dummies, the features in training and testing set will mismatch and create some overhead during prediction. So it is better to drop rows with airlocation as 'Holand-netherlands' in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "gB7c1ekYwvdf",
    "outputId": "68226417-f64d-4b2d-bf8e-4e949984ad3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>realtionship_status</th>\n",
       "      <th>industry</th>\n",
       "      <th>genre</th>\n",
       "      <th>targeted_sex</th>\n",
       "      <th>average_runtime(minutes_per_week)</th>\n",
       "      <th>airtime</th>\n",
       "      <th>airlocation</th>\n",
       "      <th>ratings</th>\n",
       "      <th>expensive</th>\n",
       "      <th>money_back_guarantee</th>\n",
       "      <th>netgain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8494</th>\n",
       "      <td>32363</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>ClassAction</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Holand-Netherlands</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25764</th>\n",
       "      <td>17205</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>ClassAction</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Holand-Netherlands</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id realtionship_status  ... money_back_guarantee netgain\n",
       "8494   32363       Never-married  ...                   No   False\n",
       "25764  17205       Never-married  ...                   No   False\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df.airlocation=='Holand-Netherlands',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEvDd_BVw7Gk"
   },
   "source": [
    "There are only 2 rows with airlocation 'Holand-Netherlands' in the training set. Droping 2 rows from the training set doesn't affect that much. So, we are going to drop those rows using their id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J5MUb7GZ_jJe"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(train_df.index[[8494,25764]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDPlKioo4SOn"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "to_be_labeled_train = ['realtionship_status','industry','genre','targeted_sex','airtime','airlocation','expensive','money_back_guarantee','netgain']\n",
    "for column in to_be_labeled_train:\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "\n",
    "to_be_labeled_test = ['realtionship_status','industry','genre','targeted_sex','airtime','airlocation','expensive','money_back_guarantee']\n",
    "for column in to_be_labeled_test:\n",
    "    test_df[column] = le.fit_transform(test_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtNeB0NJ4Xxd"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "columns = ['average_runtime(minutes_per_week)','ratings']\n",
    "for col in columns:\n",
    "    train_df[col+'_scaled'] = scale.fit_transform(np.array(train_df[col]).reshape(-1, 1))\n",
    "    test_df[col+'_scaled'] = scale.fit_transform(np.array(test_df[col]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8einxnd4bXL"
   },
   "outputs": [],
   "source": [
    "train_df.drop(columns,axis=1,inplace=True)\n",
    "train_df = train_df.drop(['id'],axis=1)\n",
    "test_df.drop(columns,axis=1,inplace=True)\n",
    "test_df = test_df.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "CdJe8hH34exT",
    "outputId": "3698fa0c-24ea-4863-c177-022c84497219"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realtionship_status</th>\n",
       "      <th>industry</th>\n",
       "      <th>genre</th>\n",
       "      <th>targeted_sex</th>\n",
       "      <th>airtime</th>\n",
       "      <th>airlocation</th>\n",
       "      <th>expensive</th>\n",
       "      <th>money_back_guarantee</th>\n",
       "      <th>netgain</th>\n",
       "      <th>average_runtime(minutes_per_week)_scaled</th>\n",
       "      <th>ratings_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617421</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777688</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.225657</td>\n",
       "      <td>0.837376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617421</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.148336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26046 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       realtionship_status  ...  ratings_scaled\n",
       "0                        3  ...       -0.148336\n",
       "1                        2  ...       -0.148336\n",
       "2                        0  ...       -0.148336\n",
       "3                        5  ...       -0.148336\n",
       "4                        2  ...       -0.148336\n",
       "...                    ...  ...             ...\n",
       "26043                    2  ...       -0.148336\n",
       "26044                    4  ...       -0.148336\n",
       "26045                    2  ...        0.837376\n",
       "26046                    4  ...       -0.148336\n",
       "26047                    2  ...       -0.148336\n",
       "\n",
       "[26046 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zh_9NrWM4guE"
   },
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,columns=['realtionship_status','industry','genre','targeted_sex','airtime','airlocation','expensive','money_back_guarantee'],drop_first=True)\n",
    "test_df = pd.get_dummies(test_df,columns=['realtionship_status','industry','genre','targeted_sex','airtime','airlocation','expensive','money_back_guarantee'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "yKKmFe0i4jX5",
    "outputId": "52341023-23be-40ef-a51a-14fcdd0922a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netgain</th>\n",
       "      <th>average_runtime(minutes_per_week)_scaled</th>\n",
       "      <th>ratings_scaled</th>\n",
       "      <th>realtionship_status_1</th>\n",
       "      <th>realtionship_status_2</th>\n",
       "      <th>realtionship_status_3</th>\n",
       "      <th>realtionship_status_4</th>\n",
       "      <th>realtionship_status_5</th>\n",
       "      <th>realtionship_status_6</th>\n",
       "      <th>industry_1</th>\n",
       "      <th>industry_2</th>\n",
       "      <th>industry_3</th>\n",
       "      <th>industry_4</th>\n",
       "      <th>industry_5</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>targeted_sex_1</th>\n",
       "      <th>airtime_1</th>\n",
       "      <th>airtime_2</th>\n",
       "      <th>airlocation_1</th>\n",
       "      <th>airlocation_2</th>\n",
       "      <th>airlocation_3</th>\n",
       "      <th>airlocation_4</th>\n",
       "      <th>airlocation_5</th>\n",
       "      <th>airlocation_6</th>\n",
       "      <th>airlocation_7</th>\n",
       "      <th>airlocation_8</th>\n",
       "      <th>airlocation_9</th>\n",
       "      <th>airlocation_10</th>\n",
       "      <th>airlocation_11</th>\n",
       "      <th>airlocation_12</th>\n",
       "      <th>airlocation_13</th>\n",
       "      <th>airlocation_14</th>\n",
       "      <th>airlocation_15</th>\n",
       "      <th>airlocation_16</th>\n",
       "      <th>airlocation_17</th>\n",
       "      <th>airlocation_18</th>\n",
       "      <th>airlocation_19</th>\n",
       "      <th>airlocation_20</th>\n",
       "      <th>airlocation_21</th>\n",
       "      <th>airlocation_22</th>\n",
       "      <th>airlocation_23</th>\n",
       "      <th>airlocation_24</th>\n",
       "      <th>airlocation_25</th>\n",
       "      <th>airlocation_26</th>\n",
       "      <th>airlocation_27</th>\n",
       "      <th>airlocation_28</th>\n",
       "      <th>airlocation_29</th>\n",
       "      <th>airlocation_30</th>\n",
       "      <th>airlocation_31</th>\n",
       "      <th>airlocation_32</th>\n",
       "      <th>airlocation_33</th>\n",
       "      <th>airlocation_34</th>\n",
       "      <th>airlocation_35</th>\n",
       "      <th>airlocation_36</th>\n",
       "      <th>airlocation_37</th>\n",
       "      <th>airlocation_38</th>\n",
       "      <th>airlocation_39</th>\n",
       "      <th>airlocation_40</th>\n",
       "      <th>expensive_1</th>\n",
       "      <th>expensive_2</th>\n",
       "      <th>money_back_guarantee_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.617421</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>1</td>\n",
       "      <td>0.777688</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.225657</td>\n",
       "      <td>0.837376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>0</td>\n",
       "      <td>0.617421</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.148336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26046 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       netgain  ...  money_back_guarantee_1\n",
       "0            0  ...                       0\n",
       "1            0  ...                       0\n",
       "2            0  ...                       1\n",
       "3            0  ...                       0\n",
       "4            1  ...                       0\n",
       "...        ...  ...                     ...\n",
       "26043        1  ...                       0\n",
       "26044        0  ...                       0\n",
       "26045        1  ...                       0\n",
       "26046        0  ...                       1\n",
       "26047        0  ...                       1\n",
       "\n",
       "[26046 rows x 64 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLwFmujjAki4"
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(['netgain'],axis=1)\n",
    "y = train_df.netgain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0Ti6FtDaWwU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "km-drKAT7L6h",
    "outputId": "55789782-19cf-47bd-d7d5-7b348365ad0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17450, 63)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ErJ6US8s68xO",
    "outputId": "d6fdbded-1cdb-4789-8763-0c1c00f47a20",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "17450/17450 [==============================] - 4s 250us/step - loss: 0.4290 - acc: 0.7799\n",
      "Epoch 2/80\n",
      "17450/17450 [==============================] - 4s 243us/step - loss: 0.3830 - acc: 0.8035\n",
      "Epoch 3/80\n",
      "17450/17450 [==============================] - 4s 226us/step - loss: 0.3788 - acc: 0.8068\n",
      "Epoch 4/80\n",
      "17450/17450 [==============================] - 4s 229us/step - loss: 0.3783 - acc: 0.8082\n",
      "Epoch 5/80\n",
      "17450/17450 [==============================] - 4s 241us/step - loss: 0.3748 - acc: 0.8062\n",
      "Epoch 6/80\n",
      "17450/17450 [==============================] - 4s 226us/step - loss: 0.3740 - acc: 0.8081\n",
      "Epoch 7/80\n",
      "17450/17450 [==============================] - 4s 232us/step - loss: 0.3711 - acc: 0.8099\n",
      "Epoch 8/80\n",
      "17450/17450 [==============================] - 4s 229us/step - loss: 0.3709 - acc: 0.8085\n",
      "Epoch 9/80\n",
      "17450/17450 [==============================] - 4s 222us/step - loss: 0.3704 - acc: 0.8072\n",
      "Epoch 10/80\n",
      "17450/17450 [==============================] - 4s 224us/step - loss: 0.3685 - acc: 0.8063\n",
      "Epoch 11/80\n",
      "17450/17450 [==============================] - 4s 229us/step - loss: 0.3688 - acc: 0.8090\n",
      "Epoch 12/80\n",
      "17450/17450 [==============================] - 4s 223us/step - loss: 0.3684 - acc: 0.8085\n",
      "Epoch 13/80\n",
      "17450/17450 [==============================] - 4s 228us/step - loss: 0.3660 - acc: 0.8111\n",
      "Epoch 14/80\n",
      "17450/17450 [==============================] - 4s 235us/step - loss: 0.3654 - acc: 0.8111\n",
      "Epoch 15/80\n",
      "17450/17450 [==============================] - 4s 233us/step - loss: 0.3674 - acc: 0.8135\n",
      "Epoch 16/80\n",
      "17450/17450 [==============================] - 4s 230us/step - loss: 0.3663 - acc: 0.8123\n",
      "Epoch 17/80\n",
      "17450/17450 [==============================] - 4s 229us/step - loss: 0.3640 - acc: 0.8137\n",
      "Epoch 18/80\n",
      "17450/17450 [==============================] - 4s 235us/step - loss: 0.3640 - acc: 0.8145\n",
      "Epoch 19/80\n",
      "17450/17450 [==============================] - 4s 216us/step - loss: 0.3619 - acc: 0.8146\n",
      "Epoch 20/80\n",
      "17450/17450 [==============================] - 4s 223us/step - loss: 0.3618 - acc: 0.8157\n",
      "Epoch 21/80\n",
      "17450/17450 [==============================] - 4s 216us/step - loss: 0.3606 - acc: 0.8131\n",
      "Epoch 22/80\n",
      "17450/17450 [==============================] - 4s 217us/step - loss: 0.3590 - acc: 0.8136\n",
      "Epoch 23/80\n",
      "17450/17450 [==============================] - 4s 233us/step - loss: 0.3605 - acc: 0.8157\n",
      "Epoch 24/80\n",
      "17450/17450 [==============================] - 4s 218us/step - loss: 0.3599 - acc: 0.8156\n",
      "Epoch 25/80\n",
      "17450/17450 [==============================] - 4s 229us/step - loss: 0.3597 - acc: 0.8158\n",
      "Epoch 26/80\n",
      "17450/17450 [==============================] - 4s 228us/step - loss: 0.3587 - acc: 0.8147\n",
      "Epoch 27/80\n",
      "17450/17450 [==============================] - 4s 236us/step - loss: 0.3592 - acc: 0.8165\n",
      "Epoch 28/80\n",
      "17450/17450 [==============================] - 4s 223us/step - loss: 0.3572 - acc: 0.8146\n",
      "Epoch 29/80\n",
      "17450/17450 [==============================] - 4s 236us/step - loss: 0.3568 - acc: 0.8146\n",
      "Epoch 30/80\n",
      "17450/17450 [==============================] - 4s 237us/step - loss: 0.3562 - acc: 0.8148\n",
      "Epoch 31/80\n",
      "17450/17450 [==============================] - 4s 221us/step - loss: 0.3555 - acc: 0.8156\n",
      "Epoch 32/80\n",
      "17450/17450 [==============================] - 4s 222us/step - loss: 0.3548 - acc: 0.8152\n",
      "Epoch 33/80\n",
      "17450/17450 [==============================] - 4s 221us/step - loss: 0.3537 - acc: 0.8144\n",
      "Epoch 34/80\n",
      "17450/17450 [==============================] - 4s 221us/step - loss: 0.3543 - acc: 0.8178\n",
      "Epoch 35/80\n",
      "17450/17450 [==============================] - 4s 219us/step - loss: 0.3537 - acc: 0.8160\n",
      "Epoch 36/80\n",
      "17450/17450 [==============================] - 4s 217us/step - loss: 0.3543 - acc: 0.8157\n",
      "Epoch 37/80\n",
      "17450/17450 [==============================] - 4s 226us/step - loss: 0.3538 - acc: 0.8179\n",
      "Epoch 38/80\n",
      "17450/17450 [==============================] - 4s 238us/step - loss: 0.3521 - acc: 0.8183\n",
      "Epoch 39/80\n",
      "17450/17450 [==============================] - 4s 214us/step - loss: 0.3516 - acc: 0.8153\n",
      "Epoch 40/80\n",
      "17450/17450 [==============================] - 4s 223us/step - loss: 0.3515 - acc: 0.8175\n",
      "Epoch 41/80\n",
      "17450/17450 [==============================] - 4s 239us/step - loss: 0.3503 - acc: 0.8183\n",
      "Epoch 42/80\n",
      "17450/17450 [==============================] - 4s 235us/step - loss: 0.3518 - acc: 0.8172\n",
      "Epoch 43/80\n",
      "17450/17450 [==============================] - 4s 250us/step - loss: 0.3494 - acc: 0.8194\n",
      "Epoch 44/80\n",
      "17450/17450 [==============================] - 4s 236us/step - loss: 0.3508 - acc: 0.8156\n",
      "Epoch 45/80\n",
      "17450/17450 [==============================] - 4s 240us/step - loss: 0.3507 - acc: 0.8188\n",
      "Epoch 46/80\n",
      "17450/17450 [==============================] - 4s 237us/step - loss: 0.3490 - acc: 0.8178\n",
      "Epoch 47/80\n",
      "17450/17450 [==============================] - 4s 240us/step - loss: 0.3500 - acc: 0.8187\n",
      "Epoch 48/80\n",
      "17450/17450 [==============================] - 4s 237us/step - loss: 0.3495 - acc: 0.8183\n",
      "Epoch 49/80\n",
      "17450/17450 [==============================] - 4s 235us/step - loss: 0.3496 - acc: 0.8182\n",
      "Epoch 50/80\n",
      "17450/17450 [==============================] - 4s 254us/step - loss: 0.3484 - acc: 0.8198\n",
      "Epoch 51/80\n",
      "17450/17450 [==============================] - 4s 238us/step - loss: 0.3480 - acc: 0.8190\n",
      "Epoch 52/80\n",
      "17450/17450 [==============================] - 4s 241us/step - loss: 0.3472 - acc: 0.8190\n",
      "Epoch 53/80\n",
      "17450/17450 [==============================] - 4s 227us/step - loss: 0.3483 - acc: 0.8198\n",
      "Epoch 54/80\n",
      "17450/17450 [==============================] - 4s 251us/step - loss: 0.3475 - acc: 0.8187\n",
      "Epoch 55/80\n",
      "17450/17450 [==============================] - 4s 246us/step - loss: 0.3464 - acc: 0.8199\n",
      "Epoch 56/80\n",
      "17450/17450 [==============================] - 4s 225us/step - loss: 0.3467 - acc: 0.8195\n",
      "Epoch 57/80\n",
      "17450/17450 [==============================] - 4s 224us/step - loss: 0.3470 - acc: 0.8194\n",
      "Epoch 58/80\n",
      "17450/17450 [==============================] - 4s 234us/step - loss: 0.3451 - acc: 0.8213\n",
      "Epoch 59/80\n",
      "17450/17450 [==============================] - 4s 235us/step - loss: 0.3445 - acc: 0.8200\n",
      "Epoch 60/80\n",
      "17450/17450 [==============================] - 4s 249us/step - loss: 0.3451 - acc: 0.8195\n",
      "Epoch 61/80\n",
      "17450/17450 [==============================] - 4s 242us/step - loss: 0.3445 - acc: 0.8213\n",
      "Epoch 62/80\n",
      "17450/17450 [==============================] - 4s 246us/step - loss: 0.3450 - acc: 0.8202\n",
      "Epoch 63/80\n",
      "17450/17450 [==============================] - 4s 227us/step - loss: 0.3434 - acc: 0.8205\n",
      "Epoch 64/80\n",
      "17450/17450 [==============================] - 4s 242us/step - loss: 0.3437 - acc: 0.8203\n",
      "Epoch 65/80\n",
      "17450/17450 [==============================] - 4s 256us/step - loss: 0.3435 - acc: 0.8203\n",
      "Epoch 66/80\n",
      "17450/17450 [==============================] - 4s 229us/step - loss: 0.3444 - acc: 0.8186\n",
      "Epoch 67/80\n",
      "17450/17450 [==============================] - 4s 241us/step - loss: 0.3444 - acc: 0.8209\n",
      "Epoch 68/80\n",
      "17450/17450 [==============================] - 4s 240us/step - loss: 0.3421 - acc: 0.8231\n",
      "Epoch 69/80\n",
      "17450/17450 [==============================] - 4s 245us/step - loss: 0.3421 - acc: 0.8180\n",
      "Epoch 70/80\n",
      "17450/17450 [==============================] - 4s 244us/step - loss: 0.3436 - acc: 0.8190\n",
      "Epoch 71/80\n",
      "17450/17450 [==============================] - 4s 236us/step - loss: 0.3417 - acc: 0.8208\n",
      "Epoch 72/80\n",
      "17450/17450 [==============================] - 4s 243us/step - loss: 0.3430 - acc: 0.8215\n",
      "Epoch 73/80\n",
      "17450/17450 [==============================] - 4s 238us/step - loss: 0.3432 - acc: 0.8219\n",
      "Epoch 74/80\n",
      "17450/17450 [==============================] - 4s 242us/step - loss: 0.3417 - acc: 0.8202\n",
      "Epoch 75/80\n",
      "17450/17450 [==============================] - 4s 246us/step - loss: 0.3414 - acc: 0.8194\n",
      "Epoch 76/80\n",
      "17450/17450 [==============================] - 4s 239us/step - loss: 0.3400 - acc: 0.8217\n",
      "Epoch 77/80\n",
      "17450/17450 [==============================] - 4s 231us/step - loss: 0.3420 - acc: 0.8222\n",
      "Epoch 78/80\n",
      "17450/17450 [==============================] - 4s 253us/step - loss: 0.3391 - acc: 0.8229\n",
      "Epoch 79/80\n",
      "17450/17450 [==============================] - 4s 238us/step - loss: 0.3405 - acc: 0.8225\n",
      "Epoch 80/80\n",
      "17450/17450 [==============================] - 4s 241us/step - loss: 0.3389 - acc: 0.8197\n",
      "-------------------------------------------------\n",
      "8596/8596 [==============================] - 1s 76us/step\n",
      "Accuracy: 81.17\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=63, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=20)\n",
    "print('-------------------------------------------------')\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B1tM2juEjUet",
    "outputId": "c5c0a187-dbb2-47dc-c9fc-d1198af1d47d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095625872498836"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4yALdO2aWnd"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "scores = []\n",
    "for i in range(1,30):\n",
    "  knn = KNeighborsClassifier(n_neighbors=i)\n",
    "  knn.fit(X_train,y_train)\n",
    "  y_pred = knn.predict(X_test)\n",
    "  scores.append(accuracy_score(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "btYVwOOOaWcx",
    "outputId": "97a5c644-1aee-43d1-f61e-33c49de8e116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.809097254536994\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(scores):\n",
    "  if j == np.array(scores).max():\n",
    "    print(i+1,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zOkHj7E7aWM1",
    "outputId": "d2d88506-3362-409d-b8f9-4160d34e2c6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065379246161005"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 1000, random_state = 0)\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "WVdyYcCHf80S",
    "outputId": "588fdf83-204f-41bb-ac17-fd32391ece09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_scores = []\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in range(len(kernels)):\n",
    "    svc_classifier = SVC(kernel = kernels[i])\n",
    "    svc_classifier.fit(X_train,y_train)\n",
    "    y_pred = svc_classifier.predict(X_test)\n",
    "    svc_scores.append(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "41Rwyq1pgmB8",
    "outputId": "eb003936-3fde-49f1-9594-f0469f86d5a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8056072591903211,\n",
       " 0.7775709632387157,\n",
       " 0.8075849232201023,\n",
       " 0.8057235923685435]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N9eJWCJy4plP",
    "outputId": "c1270e49-f122-45dc-b29a-a0643d8a5b0a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "26046/26046 [==============================] - 7s 259us/step - loss: 0.4183 - acc: 0.7829\n",
      "Epoch 2/80\n",
      "26046/26046 [==============================] - 6s 231us/step - loss: 0.3856 - acc: 0.8068\n",
      "Epoch 3/80\n",
      "26046/26046 [==============================] - 6s 243us/step - loss: 0.3792 - acc: 0.8077\n",
      "Epoch 4/80\n",
      "26046/26046 [==============================] - 6s 239us/step - loss: 0.3737 - acc: 0.8105\n",
      "Epoch 5/80\n",
      "26046/26046 [==============================] - 6s 235us/step - loss: 0.3726 - acc: 0.8090\n",
      "Epoch 6/80\n",
      "26046/26046 [==============================] - 6s 228us/step - loss: 0.3698 - acc: 0.8096\n",
      "Epoch 7/80\n",
      "26046/26046 [==============================] - 6s 223us/step - loss: 0.3682 - acc: 0.8131\n",
      "Epoch 8/80\n",
      "26046/26046 [==============================] - 6s 240us/step - loss: 0.3684 - acc: 0.8110\n",
      "Epoch 9/80\n",
      "26046/26046 [==============================] - 6s 228us/step - loss: 0.3667 - acc: 0.8131\n",
      "Epoch 10/80\n",
      "26046/26046 [==============================] - 6s 222us/step - loss: 0.3661 - acc: 0.8134\n",
      "Epoch 11/80\n",
      "26046/26046 [==============================] - 6s 235us/step - loss: 0.3658 - acc: 0.8147\n",
      "Epoch 12/80\n",
      "26046/26046 [==============================] - 6s 221us/step - loss: 0.3645 - acc: 0.8127\n",
      "Epoch 13/80\n",
      "26046/26046 [==============================] - 6s 230us/step - loss: 0.3642 - acc: 0.8135\n",
      "Epoch 14/80\n",
      "26046/26046 [==============================] - 6s 244us/step - loss: 0.3639 - acc: 0.8137\n",
      "Epoch 15/80\n",
      "26046/26046 [==============================] - 6s 241us/step - loss: 0.3628 - acc: 0.8120\n",
      "Epoch 16/80\n",
      "26046/26046 [==============================] - 6s 235us/step - loss: 0.3621 - acc: 0.8137\n",
      "Epoch 17/80\n",
      "26046/26046 [==============================] - 6s 238us/step - loss: 0.3633 - acc: 0.8146\n",
      "Epoch 18/80\n",
      "26046/26046 [==============================] - 7s 253us/step - loss: 0.3616 - acc: 0.8139\n",
      "Epoch 19/80\n",
      "26046/26046 [==============================] - 6s 229us/step - loss: 0.3623 - acc: 0.8138\n",
      "Epoch 20/80\n",
      "26046/26046 [==============================] - 6s 224us/step - loss: 0.3609 - acc: 0.8136\n",
      "Epoch 21/80\n",
      "26046/26046 [==============================] - 6s 228us/step - loss: 0.3609 - acc: 0.8126\n",
      "Epoch 22/80\n",
      "26046/26046 [==============================] - 6s 226us/step - loss: 0.3599 - acc: 0.8138\n",
      "Epoch 23/80\n",
      "26046/26046 [==============================] - 5s 210us/step - loss: 0.3599 - acc: 0.8133\n",
      "Epoch 24/80\n",
      "26046/26046 [==============================] - 6s 230us/step - loss: 0.3601 - acc: 0.8147\n",
      "Epoch 25/80\n",
      "26046/26046 [==============================] - 6s 216us/step - loss: 0.3597 - acc: 0.8156\n",
      "Epoch 26/80\n",
      "26046/26046 [==============================] - 6s 229us/step - loss: 0.3593 - acc: 0.8150\n",
      "Epoch 27/80\n",
      "26046/26046 [==============================] - 6s 219us/step - loss: 0.3583 - acc: 0.8176\n",
      "Epoch 28/80\n",
      "26046/26046 [==============================] - 6s 238us/step - loss: 0.3575 - acc: 0.8140\n",
      "Epoch 29/80\n",
      "26046/26046 [==============================] - 6s 236us/step - loss: 0.3570 - acc: 0.8165\n",
      "Epoch 30/80\n",
      "26046/26046 [==============================] - 5s 211us/step - loss: 0.3574 - acc: 0.8161\n",
      "Epoch 31/80\n",
      "26046/26046 [==============================] - 6s 229us/step - loss: 0.3573 - acc: 0.8131\n",
      "Epoch 32/80\n",
      "26046/26046 [==============================] - 5s 209us/step - loss: 0.3574 - acc: 0.8161\n",
      "Epoch 33/80\n",
      "26046/26046 [==============================] - 6s 220us/step - loss: 0.3562 - acc: 0.8169\n",
      "Epoch 34/80\n",
      "26046/26046 [==============================] - 6s 213us/step - loss: 0.3567 - acc: 0.8165\n",
      "Epoch 35/80\n",
      "26046/26046 [==============================] - 6s 220us/step - loss: 0.3555 - acc: 0.8177\n",
      "Epoch 36/80\n",
      "26046/26046 [==============================] - 6s 214us/step - loss: 0.3556 - acc: 0.8177\n",
      "Epoch 37/80\n",
      "26046/26046 [==============================] - 6s 220us/step - loss: 0.3554 - acc: 0.8174\n",
      "Epoch 38/80\n",
      "26046/26046 [==============================] - 6s 216us/step - loss: 0.3556 - acc: 0.8151\n",
      "Epoch 39/80\n",
      "26046/26046 [==============================] - 6s 212us/step - loss: 0.3550 - acc: 0.8174\n",
      "Epoch 40/80\n",
      "26046/26046 [==============================] - 6s 213us/step - loss: 0.3550 - acc: 0.8182\n",
      "Epoch 41/80\n",
      "26046/26046 [==============================] - 6s 217us/step - loss: 0.3550 - acc: 0.8175\n",
      "Epoch 42/80\n",
      "26046/26046 [==============================] - 6s 224us/step - loss: 0.3546 - acc: 0.8176\n",
      "Epoch 43/80\n",
      "26046/26046 [==============================] - 6s 212us/step - loss: 0.3541 - acc: 0.8186\n",
      "Epoch 44/80\n",
      "26046/26046 [==============================] - 5s 210us/step - loss: 0.3540 - acc: 0.8167\n",
      "Epoch 45/80\n",
      "26046/26046 [==============================] - 6s 226us/step - loss: 0.3536 - acc: 0.8196\n",
      "Epoch 46/80\n",
      "26046/26046 [==============================] - 6s 220us/step - loss: 0.3534 - acc: 0.8172\n",
      "Epoch 47/80\n",
      "26046/26046 [==============================] - 6s 218us/step - loss: 0.3528 - acc: 0.8186\n",
      "Epoch 48/80\n",
      "26046/26046 [==============================] - 6s 215us/step - loss: 0.3529 - acc: 0.8182\n",
      "Epoch 49/80\n",
      "26046/26046 [==============================] - 6s 213us/step - loss: 0.3512 - acc: 0.8192\n",
      "Epoch 50/80\n",
      "26046/26046 [==============================] - 6s 212us/step - loss: 0.3528 - acc: 0.8179\n",
      "Epoch 51/80\n",
      "26046/26046 [==============================] - 6s 215us/step - loss: 0.3511 - acc: 0.8172\n",
      "Epoch 52/80\n",
      "26046/26046 [==============================] - 5s 208us/step - loss: 0.3515 - acc: 0.8170\n",
      "Epoch 53/80\n",
      "26046/26046 [==============================] - 6s 214us/step - loss: 0.3520 - acc: 0.8165\n",
      "Epoch 54/80\n",
      "26046/26046 [==============================] - 6s 222us/step - loss: 0.3519 - acc: 0.8196\n",
      "Epoch 55/80\n",
      "26046/26046 [==============================] - 6s 222us/step - loss: 0.3519 - acc: 0.8183\n",
      "Epoch 56/80\n",
      "26046/26046 [==============================] - 6s 217us/step - loss: 0.3510 - acc: 0.8198\n",
      "Epoch 57/80\n",
      "26046/26046 [==============================] - 6s 218us/step - loss: 0.3514 - acc: 0.8192\n",
      "Epoch 58/80\n",
      "26046/26046 [==============================] - 6s 220us/step - loss: 0.3507 - acc: 0.8177\n",
      "Epoch 59/80\n",
      "26046/26046 [==============================] - 6s 216us/step - loss: 0.3511 - acc: 0.8186\n",
      "Epoch 60/80\n",
      "26046/26046 [==============================] - 5s 207us/step - loss: 0.3502 - acc: 0.8188\n",
      "Epoch 61/80\n",
      "26046/26046 [==============================] - 5s 209us/step - loss: 0.3506 - acc: 0.8198\n",
      "Epoch 62/80\n",
      "26046/26046 [==============================] - 6s 211us/step - loss: 0.3505 - acc: 0.8194\n",
      "Epoch 63/80\n",
      "26046/26046 [==============================] - 6s 217us/step - loss: 0.3497 - acc: 0.8195\n",
      "Epoch 64/80\n",
      "26046/26046 [==============================] - 6s 218us/step - loss: 0.3482 - acc: 0.8213\n",
      "Epoch 65/80\n",
      "26046/26046 [==============================] - 6s 215us/step - loss: 0.3492 - acc: 0.8192\n",
      "Epoch 66/80\n",
      "26046/26046 [==============================] - 6s 224us/step - loss: 0.3490 - acc: 0.8186\n",
      "Epoch 67/80\n",
      "26046/26046 [==============================] - 6s 226us/step - loss: 0.3481 - acc: 0.8204\n",
      "Epoch 68/80\n",
      "26046/26046 [==============================] - 6s 218us/step - loss: 0.3484 - acc: 0.8187\n",
      "Epoch 69/80\n",
      "26046/26046 [==============================] - 6s 218us/step - loss: 0.3491 - acc: 0.8172\n",
      "Epoch 70/80\n",
      "26046/26046 [==============================] - 6s 215us/step - loss: 0.3478 - acc: 0.8230\n",
      "Epoch 71/80\n",
      "26046/26046 [==============================] - 5s 204us/step - loss: 0.3476 - acc: 0.8208\n",
      "Epoch 72/80\n",
      "26046/26046 [==============================] - 6s 214us/step - loss: 0.3479 - acc: 0.8181\n",
      "Epoch 73/80\n",
      "26046/26046 [==============================] - 6s 215us/step - loss: 0.3485 - acc: 0.8203\n",
      "Epoch 74/80\n",
      "26046/26046 [==============================] - 6s 226us/step - loss: 0.3470 - acc: 0.8200\n",
      "Epoch 75/80\n",
      "26046/26046 [==============================] - 6s 216us/step - loss: 0.3469 - acc: 0.8205\n",
      "Epoch 76/80\n",
      "26046/26046 [==============================] - 6s 214us/step - loss: 0.3469 - acc: 0.8195\n",
      "Epoch 77/80\n",
      "26046/26046 [==============================] - 6s 219us/step - loss: 0.3468 - acc: 0.8220\n",
      "Epoch 78/80\n",
      "26046/26046 [==============================] - 6s 216us/step - loss: 0.3476 - acc: 0.8212\n",
      "Epoch 79/80\n",
      "26046/26046 [==============================] - 6s 213us/step - loss: 0.3462 - acc: 0.8210\n",
      "Epoch 80/80\n",
      "26046/26046 [==============================] - 6s 217us/step - loss: 0.3465 - acc: 0.8206\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# logreg = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "# logreg.fit(X,y)\n",
    "# y_pred = knn.predict(test_df)\n",
    "# final_df = pd.DataFrame({'id': id, 'netgain': y_pred})\n",
    "# final_df['netgain'] = final_df['netgain'].map({0:False,1:True})\n",
    "# final_df.to_csv('logreg_Results.csv',index=False)\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=19)\n",
    "# knn.fit(X,y)\n",
    "# y_pred = knn.predict(test_df)\n",
    "# final_df = pd.DataFrame({'id': id, 'netgain': y_pred})\n",
    "# final_df['netgain'] = final_df['netgain'].map({0:False,1:True})\n",
    "# final_df.to_csv('knn_Results.csv',index=False)\n",
    "\n",
    "\n",
    "# rf_classifier = RandomForestClassifier(n_estimators = 1000, random_state = 0)\n",
    "# rf_classifier.fit(X,y)\n",
    "# y_pred = rf_classifier.predict(test_df)\n",
    "# final_df = pd.DataFrame({'id': id, 'netgain': y_pred})\n",
    "# final_df['netgain'] = final_df['netgain'].map({0:False,1:True})\n",
    "# final_df.to_csv('rf_Results.csv',index=False)\n",
    "\n",
    "# svc_classifier = SVC(kernel = 'rbf')\n",
    "# svc_classifier.fit(X,y)\n",
    "# y_pred = svc_classifier.predict(test_df)\n",
    "# final_df = pd.DataFrame({'id': id, 'netgain': y_pred})\n",
    "# final_df['netgain'] = final_df['netgain'].map({0:False,1:True})\n",
    "# final_df.to_csv('svc_Results.csv',index=False)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=63, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "model.fit(X,y, epochs=80, batch_size=20)\n",
    "print('-------------------------------------------------------------------------')\n",
    "y_pred = model.predict_classes(test_df)\n",
    "final_df = pd.DataFrame({'id': id, 'netgain': y_pred.flatten()})\n",
    "final_df['netgain'] = final_df['netgain'].map({0:False,1:True})\n",
    "final_df.to_csv('nn_Results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ad Success.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
